{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaniYamin/repo/blob/main/FashionMNIST_NeuralNetwork_DL_numpy_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XDDbguyGU8Fs"
      },
      "source": [
        "# Mid-semester assignment Part 1 - Basics of deep learning\n",
        "Hello dear students,<br> this is the template notebook. Please upload it into your drive and open as Google Colab nootebook\".\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### Name and ID:\n",
        "Student 1: Noam Meir \n",
        "<br>\n",
        "Student 2: Shani Yamin "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLkWLC8f3HZI"
      },
      "source": [
        "## Fashion MNIST\n",
        "Fashion MNIST dataset contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  \n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiRxNFCn3Vxd"
      },
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `train_images` and `train_labels` arrays are the *training set*â€”the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "\n",
        "# Goodluck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4K84YZ_QU8Fv"
      },
      "source": [
        "#Neural Network in plain NumPy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QReFpU112hLT"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLOHjUiFU8Fv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5MsCpUv2tuj"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbzv9ZYA2pyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3899909-3938-45b7-ccc2-729209b9c0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784) (70000,)\n"
          ]
        }
      ],
      "source": [
        "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True, as_frame=False)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPBGGKtSoVpU"
      },
      "source": [
        "## Data preprocessing (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZfq8otp-wXY"
      },
      "source": [
        "### Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MZtZIzzDIKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab416d32-f2b6-412c-e08e-93dd8b48959a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 70000)\n",
            "(1, 70000)\n"
          ]
        }
      ],
      "source": [
        "examples = y.shape[0]\n",
        "y1 = y.reshape(1, examples)\n",
        "X1 = X / 255\n",
        "X1 = X1.T\n",
        "print(X1.shape)\n",
        "print(y1.shape) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6K01j7A_Z4W"
      },
      "source": [
        "### Select two classes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "choose what labels we are going to learn, create a new matrix (X-Data) from all data to the relevant labels,\n",
        "so the matrix sizes will be (amount of the labels that are relevant, 784 for the pixels in the pictures)\n",
        "and create new labels matrix that includes only label0,label1. \n",
        "At the labels(y)Put 0.0 for label0 and 1.0 for label1, to classify success or failure for our learning."
      ],
      "metadata": {
        "id": "-gfsj-2LGSi3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OuPZ0o8DNWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "402fe0ab-fc57-446c-9f14-3149a56b46dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14000, 784)\n",
            "(14000, 1)\n"
          ]
        }
      ],
      "source": [
        "#TODO: select two classes (for example 2-Pullover and 4-Coat)\n",
        "labels=[]\n",
        "matrix=[]\n",
        "label0='5'\n",
        "label1='9'\n",
        "X2=np.transpose(X1)\n",
        "for i, value in enumerate(y1[0]):\n",
        "  if value==label0 or value ==label1:\n",
        "    if value==label0:\n",
        "      labels.append(0.0)\n",
        "    else:\n",
        "      labels.append(1.0)\n",
        "    row=X2[i,:]\n",
        "    matrix.append(row)\n",
        "\n",
        "matrix=np.asarray(matrix)\n",
        "print(matrix.shape)\n",
        "labels=np.asarray(labels).reshape(len(labels),1)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn5UPcIQH2jS"
      },
      "source": [
        "### Split the data into Train set and Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine X,and Y by the data matrix and labels matrix.\n",
        "Split the data into Train set and Test set."
      ],
      "metadata": {
        "id": "V53_3e4XGPe9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBUI2DZmhd0y"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the data into Train set and Test set (The use of libraries other than Numpy is strictly prohibited)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X = matrix\n",
        "Y = labels\n",
        "\n",
        "# Use shuffle on the train data\n",
        "X, y = shuffle(X, Y)\n",
        "\n",
        "split_pct = int(0.7*int(len(X)))\n",
        "X_train, X_test = np.transpose(X[:split_pct]),np.transpose(X[split_pct:])\n",
        "Y_train, Y_test = y[:split_pct],y[split_pct:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg7D7fwGH9Yv"
      },
      "source": [
        "### Test yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkLl0PSyDR9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c0ed705b-1410-4326-c6a9-e9fb230a65ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Test yourself (Check that the classes you have selected are actually displayed)\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "i = random.randint(100)\n",
        "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_train[i,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81OW5M7oCWZ"
      },
      "source": [
        "## Activation functions (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implement sigmoid function"
      ],
      "metadata": {
        "id": "15eBIUmIGLhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxruxXBsDmP-"
      },
      "outputs": [],
      "source": [
        "#TODO: Sigmoid activation function\n",
        "def sigmoid(z):\n",
        "  newZ=np.float128(z)\n",
        "  return 1/(1+np.exp(-newZ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIAUcVboOG9"
      },
      "source": [
        "## Loss function (20%)\n",
        "BCE Loss function captures the intuition that the neural network should pay a high penalty(Lossâ†’âˆž) when the estimated probability, with respect to the training exampleâ€™s label, is completely wrong. On the other hand, the Loss should equal zero(Loss=0) when the estimated probability, with respect to the training exampleâ€™s label, is correct. Simply put, the BCE Loss should equal zero in only two instances:<br>\n",
        "* if the example is positively labeled(y=1) the neural network model should be completely sure that the example belongs to the positive class i.e pÌ‚=1.\n",
        "* if the example is negatively labeled(y=0) the neural network model should be completely sure that the example does not belong to the positive class i.e pÌ‚=0.\n",
        "\n",
        "<b> When we work with a computer, there are very high values or very low values that it cannot handle and that could cause the system to crash. <br>In order to overcome the case where the function returns values that strive for infinity you will need to understand which range of values causes the logarithm to return inf \\ -inf and handle this within the function. </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "   implement binary cross entropy that compares each of the predicted probabilities to actual class output which can be either 0 or 1."
      ],
      "metadata": {
        "id": "ur6ehEM1GEMp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0i2o9_KDUdQ"
      },
      "outputs": [],
      "source": [
        "#TODO: Binary cross entropy\n",
        "def log_loss(y_hat, Y):\n",
        "    '''\n",
        "    Logistic loss, assuming a single value in y_hat and y.\n",
        "    '''\n",
        "    return -(Y * np.log(y_hat) + (1 - Y) * (np.log(1 - y_hat))).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY9DQPrJmvHZ"
      },
      "source": [
        "## NN Hyper Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "choose the variables which determines the network structure(Hidden Layer) \n",
        "and the variables which determine how the network is trained(Learning Rate)"
      ],
      "metadata": {
        "id": "bNIfhUaLF87n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGCU_QYRnJap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19fc1b1-c82e-417a-af05-3ca83c9f00e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9800\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_layer = X_train.shape[0] # 28X28 = 784\n",
        "print(len(X_train[0]))\n",
        "hidden_layer = 5 \n",
        "learning_rate = 0.01 \n",
        "epochs = 100 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SdHpc2m3vV"
      },
      "source": [
        "## Weight and Bias Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the weight and bias "
      ],
      "metadata": {
        "id": "1xB61v40Fu61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVRoMGxTnLZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029c211d-2cf6-4d1e-aec2-61b3a48099a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 784)\n",
            "(5, 1)\n",
            "(1, 5)\n",
            "(1, 1)\n",
            "(14000, 784)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "W1 = np.random.randn(hidden_layer, input_layer)\n",
        "b1 = np.zeros((hidden_layer, 1))\n",
        "W2 = np.random.randn(1, hidden_layer)\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "print(W1.shape)\n",
        "# print(W1)\n",
        "print(b1.shape)\n",
        "# print(b1)\n",
        "print(W2.shape)\n",
        "# print(W2)\n",
        "print(b2.shape)\n",
        "# print(b2)\n",
        "print(X.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp-IaWECn6Hu"
      },
      "source": [
        "## Training (30%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tdlcCGLDo7F",
        "outputId": "669f8191-62cf-4376-c294-2b4b389cfeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0  Loss: 0.46189106583561525925\n",
            "Epoch 1  Loss: 0.23578913956730340896\n",
            "Epoch 2  Loss: 0.16750731098718424676\n",
            "Epoch 3  Loss: 0.13510721074524825782\n",
            "Epoch 4  Loss: 0.11472889703185643879\n",
            "Epoch 5  Loss: 0.10075406866516066915\n",
            "Epoch 6  Loss: 0.090879013090967342937\n",
            "Epoch 7  Loss: 0.083548590797878362586\n",
            "Epoch 8  Loss: 0.07759432043576903036\n",
            "Epoch 9  Loss: 0.07252099732713469425\n",
            "Epoch 10  Loss: 0.06814570951238221272\n",
            "Epoch 11  Loss: 0.064180344458510653874\n",
            "Epoch 12  Loss: 0.060494407874811617803\n",
            "Epoch 13  Loss: 0.05714838288791272672\n",
            "Epoch 14  Loss: 0.05414647324599669224\n",
            "Epoch 15  Loss: 0.05150155562302795484\n",
            "Epoch 16  Loss: 0.049089294603696023136\n",
            "Epoch 17  Loss: 0.046861887299262572197\n",
            "Epoch 18  Loss: 0.044854616025497832462\n",
            "Epoch 19  Loss: 0.04309075074301748765\n",
            "Epoch 20  Loss: 0.041520795560997989392\n",
            "Epoch 21  Loss: 0.040083534629671078095\n",
            "Epoch 22  Loss: 0.03874000225215130382\n",
            "Epoch 23  Loss: 0.03747506158686168725\n",
            "Epoch 24  Loss: 0.03628933836179979756\n",
            "Epoch 25  Loss: 0.035182501468003496847\n",
            "Epoch 26  Loss: 0.03414572997359412457\n",
            "Epoch 27  Loss: 0.033171179087787470183\n",
            "Epoch 28  Loss: 0.032256920551496914747\n",
            "Epoch 29  Loss: 0.031390720907643574606\n",
            "Epoch 30  Loss: 0.030548715948638731276\n",
            "Epoch 31  Loss: 0.029700523615703166269\n",
            "Epoch 32  Loss: 0.028802370982922127343\n",
            "Epoch 33  Loss: 0.028002436223377087721\n",
            "Epoch 34  Loss: 0.027318878327114273541\n",
            "Epoch 35  Loss: 0.02669048711319268191\n",
            "Epoch 36  Loss: 0.026097936046939976957\n",
            "Epoch 37  Loss: 0.025529231419652427799\n",
            "Epoch 38  Loss: 0.024977183054921746404\n",
            "Epoch 39  Loss: 0.024438858298282561758\n",
            "Epoch 40  Loss: 0.023915870805118506078\n",
            "Epoch 41  Loss: 0.023411755766761957804\n",
            "Epoch 42  Loss: 0.022928078005364086958\n",
            "Epoch 43  Loss: 0.022463670311699515092\n",
            "Epoch 44  Loss: 0.022016170843852553858\n",
            "Epoch 45  Loss: 0.0215832844834006385\n",
            "Epoch 46  Loss: 0.021163263001788838663\n",
            "Epoch 47  Loss: 0.020755047142839022561\n",
            "Epoch 48  Loss: 0.020358046303118057115\n",
            "Epoch 49  Loss: 0.01997150955049276931\n",
            "Epoch 50  Loss: 0.019594259777369676738\n",
            "Epoch 51  Loss: 0.01922535050576803632\n",
            "Epoch 52  Loss: 0.018863658021285651804\n",
            "Epoch 53  Loss: 0.01850684084049626301\n",
            "Epoch 54  Loss: 0.018161825399515954207\n",
            "Epoch 55  Loss: 0.017844318533926486132\n",
            "Epoch 56  Loss: 0.017554081185625417575\n",
            "Epoch 57  Loss: 0.017282513461333865776\n",
            "Epoch 58  Loss: 0.017023388711744584619\n",
            "Epoch 59  Loss: 0.01677334082072469555\n",
            "Epoch 60  Loss: 0.01653106873129567722\n",
            "Epoch 61  Loss: 0.01629654620122135408\n",
            "Epoch 62  Loss: 0.01606998911991486441\n",
            "Epoch 63  Loss: 0.015851207174535910746\n",
            "Epoch 64  Loss: 0.015639672435610618375\n",
            "Epoch 65  Loss: 0.015434380498685207321\n",
            "Epoch 66  Loss: 0.015233282231164947503\n",
            "Epoch 67  Loss: 0.015034319720051238232\n",
            "Epoch 68  Loss: 0.014839547682747729759\n",
            "Epoch 69  Loss: 0.014655425330653167652\n",
            "Epoch 70  Loss: 0.014484617008029898115\n",
            "Epoch 71  Loss: 0.014324893228747143242\n",
            "Epoch 72  Loss: 0.01417355426446218724\n",
            "Epoch 73  Loss: 0.014028691497384335263\n",
            "Epoch 74  Loss: 0.013888929364476376261\n",
            "Epoch 75  Loss: 0.013753163700336394477\n",
            "Epoch 76  Loss: 0.013620438643025026276\n",
            "Epoch 77  Loss: 0.013489891030732365445\n",
            "Epoch 78  Loss: 0.013360725282416857332\n",
            "Epoch 79  Loss: 0.0132322189605014940716\n",
            "Epoch 80  Loss: 0.013103782317534990125\n",
            "Epoch 81  Loss: 0.012975109301626687686\n",
            "Epoch 82  Loss: 0.0128464385149099463095\n",
            "Epoch 83  Loss: 0.012718816265106289877\n",
            "Epoch 84  Loss: 0.0125940117566921335985\n",
            "Epoch 85  Loss: 0.012473789785646831362\n",
            "Epoch 86  Loss: 0.0123590327457856452765\n",
            "Epoch 87  Loss: 0.012249595682957063925\n",
            "Epoch 88  Loss: 0.012144818742233615706\n",
            "Epoch 89  Loss: 0.012044014213186426989\n",
            "Epoch 90  Loss: 0.011946672131606041559\n",
            "Epoch 91  Loss: 0.01185248463927896119\n",
            "Epoch 92  Loss: 0.011761296358856875774\n",
            "Epoch 93  Loss: 0.01167302546157260599\n",
            "Epoch 94  Loss: 0.011587577365739877807\n",
            "Epoch 95  Loss: 0.011504773953847005169\n",
            "Epoch 96  Loss: 0.011424316079358136772\n",
            "Epoch 97  Loss: 0.011345778021921966753\n",
            "Epoch 98  Loss: 0.011268614802410794423\n",
            "Epoch 99  Loss: 0.011192161313399643792\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "'''\n",
        "X = X_train\n",
        "Y = Y_train\n",
        "loss_list = []\n",
        "epoch_list = []\n",
        "\n",
        "numOfTraining = len(X_train[1])# Write the number of examples in your train set\n",
        "for i in range(epochs):\n",
        "  avg_epoch_loss = 0\n",
        "  for j in range(numOfTraining):\n",
        "    # TODO :  Forward propagation\n",
        "    '''\n",
        "    where input data is fed through a network, in a forward direction, to generate an output\n",
        "    '''\n",
        "    X_j = X[:,j].reshape(X[:,j].shape[0],1)\n",
        "    Z1 = np.dot(W1, X_j) + b1 # DO NOT FORGET TO ADD THE BIAS\n",
        "    A1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    Yout = int(Y[j])\n",
        "    \n",
        "\n",
        "    # TODO: Compute loss\n",
        "    loss = log_loss( A2, Yout)\n",
        "    avg_epoch_loss = avg_epoch_loss + loss\n",
        "    \n",
        "    # TODO: Back propagation\n",
        "    '''\n",
        "    implement the algorithm that is designed to test for errors working back from output nodes to input nodes\n",
        "    We gave the machine the derivative of the data because we want the weights to change in accordance with the success and the failure.\n",
        "    '''\n",
        "    dZ2 = A2 - Yout\n",
        "    dW2 = np.dot(dZ2, A1.T)\n",
        "    db2 = dZ2\n",
        "\n",
        "    dZ1 = A1* (1 - A1)*np.dot(W2.T, dZ2)\n",
        "    dW1 = np.dot(dZ1, X_j.T)\n",
        "    db1 = dZ1\n",
        "\n",
        "    # TODO: Update weights\n",
        "    '''\n",
        "    updating the weights according to our feedback from the derivative of the last place in the neural network.\n",
        "    '''\n",
        "    W1 = W1 - learning_rate * dW1 \n",
        "    b1 = b1 - learning_rate * db1 \n",
        "    W2 = W2 - learning_rate * dW2 \n",
        "    b2 = b2 - learning_rate * db2 \n",
        "  avg_epoch_loss = avg_epoch_loss/numOfTraining\n",
        "  loss_list.append(avg_epoch_loss)\n",
        "  epoch_list.append(i)\n",
        "  print(\"Epoch\", i,\" Loss:\", avg_epoch_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdgCk97534-B"
      },
      "source": [
        "### Loss Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFo9NN5Q31X8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "841cbf82-83b3-498d-d48f-d61705712db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f52a0bb3640>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(epoch_list, loss_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HV5g7j92Xfn"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raBFclM5ploH"
      },
      "source": [
        "### Test your performance (30%)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking if our train and NN Hyper Parameters are training well and if our accuracy is accurate"
      ],
      "metadata": {
        "id": "MDXSW3A6GcdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flfh-luxDs7Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86de4c53-808f-4a39-fc3b-bea2b5077ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2118   41]\n",
            " [  43 1998]]\n",
            "Accuracy:  98.0 %\n"
          ]
        }
      ],
      "source": [
        "#TODO: Forward batch of examples\n",
        "X = X_test\n",
        "Y = Y_test\n",
        "\n",
        "Z1 = np.dot(W1, X) + b1\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "\n",
        "predictions = np.zeros((1,Y.shape[0]))\n",
        "labels = np.zeros((1,Y.shape[0]))\n",
        "\n",
        "# Check your predictions against the test's labels\n",
        "for i in range(Y.shape[0]):\n",
        "  if (A2[0,i] > 0.5): \n",
        "    predictions[0,i] = 1\n",
        "  labels[0,i] = Y[i,0]\n",
        "\n",
        "confusion = confusion_matrix(predictions.T, labels.T)\n",
        "confcalc = (confusion[0,0]+confusion[1,1])/(confusion[0,0]+confusion[0,1]+confusion[1,0]+confusion[1,1])\n",
        "# Print the confusion matrix In order to test your performance\n",
        "print(confusion)\n",
        "print(\"Accuracy: \",(int(confcalc*10000)/100),\"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FtZr0EQBlcm"
      },
      "source": [
        "### Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAj_5W2wVUrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8b5b3da7-a4b0-4bec-bfbd-235a93ce802d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "Real= 0.0 Predicted= [[5.46157571e-06]]\n"
          ]
        }
      ],
      "source": [
        "#TODO: SHOW VISUALLY RESULTS ON 10 TEST EXAMPLES\n",
        "%matplotlib inline\n",
        "from numpy import random\n",
        "\n",
        "i = random.randint(2000)\n",
        "plt.imshow(X_test[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "Y_test[i,0]\n",
        "\n",
        "\n",
        "Z1 = np.dot(W1,X_test[:,i])\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)\n",
        "\n",
        "Yout = Y[i,0]\n",
        "print(Yout)\n",
        "print(\"Real=\", Y_test[i,0], \"Predicted=\",A2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}